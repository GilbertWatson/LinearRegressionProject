\documentclass{article}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{times}
\usepackage{enumerate}

\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in


%------------------------------------------------------------
% newcommand
%------------------------------------------------------------
\newcommand{\scscst}{\scriptscriptstyle}
\newcommand{\scst}{\scriptstyle}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rexpression}[1]{\texttt{#1}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}

\begin{document}
\SweaveOpts{concordance=TRUE}

%------------------------------------------------------------
\title{Regression Analysis of Higher Education Outcomes}
%------------------------------------------------------------
\author{Gilbert Watson}
\date{Monday, November 25th, 2013}

\SweaveOpts{highlight=TRUE, tidy=TRUE, keep.space=TRUE, keep.blank.space=FALSE, keep.comment=TRUE}
\SweaveOpts{prefix.string=Fig}


\maketitle
\tableofcontents

%-------------------------------------------
\section{Introduction}
%-------------------------------------------

Higher education is big business blah, blah, blah, blah.

%-------------------------------------------
\section{The Data}
%-------------------------------------------

\subsection{Raw Data}
Data on five year graduate rates, tuition and fees, and other post-secondary institutional characteristics are available through the US Department of Education's National Center for Education Statistics (NCES). For this study, we chose to only consider data for those institutions that possess the following characteristics:

\begin{enumerate}[a)]
\item{} Title IV participating
\item{} US only
\item{} Carnegie Foundation ranking in a research, doctoral, or baccalaureate category
\item{} The institution has at least some full-time undergraduates
\item{} The institution has at least one program that is not offered through distance education
\item{} No for-profit institutions, only public and not-for-profit
\end{enumerate}

The survey that collects this data is administered yearly, but for this study, we chose to only consider the cross section available from the 2010 survey. We do not intend to examine the time dynamics of institutional characteristics.

The original dataset contains 1499 observational units and 320 variables. Variables contain data on characteristics such as admission rates, admission yeilds, tuition and other costs, student body demographics, graduation rates, averages and percentages of students recieving various types of aid, pay rates for different types of university faculty, and various institutional financials on a per faculty basis. In particular, this paper seeks to examine two of these variables relationships to the others - five year undergraduate graduation rates and 2010-2011 educational year tuition and fees. What institutional characteristics are associated with strong educational outcomes (a high graduation rate) and does this have any relationship to the institutional determinants of high cost? A quick examination would show that there is in fact a relationship. A scatter plot of five year graduation rates and tuition and fees shows the existence of a strong relationship, and beyond that a relationship that is bifurcated between private and public institutions. This isn't surprising. Elite educational institutions often cost more and often have higher graduation rates if for no other reason than they attract top notch students. There is a bit of self selction bias going on. This paper is not concerned with this relationship alone. We are concerned about the individual predictors associated with tuition and fees (of which graduate rates may be one) and the individual predictors of graduation rates. Are the predictors similar, or are they determined by wholy different factors when accounting for things like selectivity?

<<sourceanalysis1,echo=FALSE,fig=TRUE,figs.only=TRUE>>=
source('Analysis.R')
require(ggplot2)
q <- ggplot(aes(x=DRVGR2011_RV.Graduation.rate...Bachelor.degree.within.5.years..total,y=DRVIC2011_RV.Tuition.and.fees..2010.11,colour=HD2011.Control.of.institution),data=data)
q + geom_point() + xlab("5 Year Graduation Rate") + ylab("Tuition and Fees (2010-2011)") + scale_colour_discrete(name="Institutional Control") + ggtitle("US Undergraduate Serving Institutions")
@

%-------------------------------------------
\section{ANOVA Analysis}
%-------------------------------------------

\subsection{One-Way ANOVA}

<<anova,results=tex>>=
library(alr3)
library(xtable)
simpleanovalm <- lm(DRVGR2011_RV.Graduation.rate...Bachelor.degree.within.5.years..total~DRVIC2011_RV.Tuition.and.fees..2010.11-1,
                    data=data)
simpleanova <- anova(simpleanovalm)
print(xtable(pureErrorAnova(simpleanovalm)))
@

\subsection{Two-Way ANOVA}

<<twoway1,results=tex>>=
anovapublicprivatelm <- lm(DRVGR2011_RV.Graduation.rate...Bachelor.degree.within.5.years..total~DRVIC2011_RV.Tuition.and.fees..2010.11 + HD2011.Control.of.institution - 1,data=data)
anovapublicprivate <- anova(anovapublicprivatelm)
print(xtable(pureErrorAnova(anovapublicprivatelm)))
@

<<extrasum1,results=tex>>=
print(xtable(anova(anovapublicprivatelm,simpleanovalm)))
@

<<twoway2,results=tex>>=
anovasectorlm <- lm(DRVGR2011_RV.Graduation.rate...Bachelor.degree.within.5.years..total~DRVIC2011_RV.Tuition.and.fees..2010.11 + HD2011.Carnegie.Classification.2010..Undergraduate.Profile,data=data)
anovasector <- anova(anovasectorlm)
print(xtable(pureErrorAnova(anovasectorlm)))
@

<<extrasum2,results=tex>>=
print(xtable(anova(anovasectorlm,simpleanovalm)))
@

\subsection{Data Cleaning}

Several steps were taken to clean the data prior to analysis. A full accounting of the steps taken is in the source code for this document, which will be made available on Github. A list of the high points which do concern the analysis follows:

\begin{enumerate}[a)]
\item{} Institutional identification variables were removed.
\item{} A small collection of variables concerning a partitular cohort of students measured by NCES was removed.
\item{} The small differences between FASB and GASB financial reporting methods for educational institutions are ignored and those variables are merged. These largely comprise per full-time equivalent institutional finance variables.
\item{} In-state and out-of-state cost variables are merged for private institutions where they have no applicability
\item{} Admission rates for institutions that only serve one gender were adjusted to zero for the appropriate gender. Additionally, a categorical variable indicating whether an institution serves males, females, or both was generated.
\item{} One pair of variables that partitioned the data were removed to eliminate the possibility of linear dependence between columns. For example, percentage of students enrolled in non-degree programs was removed as a variable in the presence of full-time and part-time enrollment because all three would perfectly partition the total enrollment variable.
\item{} Several variable transformations were preformed before analysis to eliminate obvious sources of colinearity. For example, the percentage of enrollment comprised of undergrads was generated to account for the fact that undergraduate enrollment and total enrollment are highly correlated. None of the original variables were removed and are still taken into consideration as predictors, but the transformations made seemed like obvious normalizations.
\item{} Variables that are missing for over 100 observations are removed from the dataset. This eliminates variables like the revenue from state appropriations since most private schools do not recieve state appropriations.
\end{enumerate}

%-------------------------------------------
\section{Dimensionality Reduction}
%-------------------------------------------

319 potential predictors is a lot of variables to deal with. In the face of this, and without any qualitative understanding of the drivers behind graduation rates and tuition and fees, an automated variable selection method was used to reduce the dataset to a manageable number of predictors. For each response variable, the following steps were taken to reduce the dataset.

\begin{enumerate}[1)]
\item{} Variables closely related to the response were removed from the dataset. For example, in the case of graduation rates, 4 and 6 year graduation rates were removed when using the 5 year graduation rate as a response variable.
\item{} The full model with all remaining candidate predictors is estimated.
\item{} Using the full model, forward, backward, and sequential automated variable selection algorithms are used to search for the best full model. Each method is was allowed to pick a set of up to 50 predictors which optimized model BIC. The union of these predictors is passed to the next step.
\item{} All but those predictors proposed by the previous step are removed from the dataset. During this step, missing values are retained. A full model with those predictors remaining is estimated. Again, the three methods choose the best model availiable to the algorithm using BIC as a criterion. Each is allowed to consider models of up to 20 predictors. The union of these predictors is passed to the next step.
\item{} Only those predictors selected by the previous step are retained in the dataset. An efficient branch-and-bound algorithm is used to search the remaining predictors for the best model. The criterion doesn't matter since the search is exhaustive. The predictors selected by this step are used as the initial step in modeling.
\end{enumerate}

The reason for using multiple stages of automated variable selection is that exhaustive search for the best model using just first order terms would be very computationally intensive. This method gives us a manageable number of predictors to begin model refinement. Even graphical search for potential predictors would have been difficult with so many potential variables. There would have been over fifty thousand paired scatter plots to consider.

%-------------------------------------------
\section{Regression Analysis: 5 Year Graduation Rates}
%-------------------------------------------

\subsection{Initial Model}

After the initial data reduction effort described above, an initial model for five year undergraduate graduation rates results. The table below gives the summary statistics for the dataset underlying the model:

<<gradrateinitial,echo=FALSE,results=tex>>=
summ <- NULL
summ$Min <- sapply(GradRate, min, na.rm=TRUE)
summ$Median <- sapply(GradRate, median, na.rm=TRUE)
summ$Mean <- sapply(GradRate, mean, na.rm=TRUE)
summ$Max <- sapply(GradRate, max, na.rm=TRUE)
summ <- as.data.frame(summ)
require(xtable)
print(xtable(summ,caption=paste0("Summary Statistics For Dataset (n = ",length(GradRate[,1]),")")))
@

A table outlining the full model associated with this dataset follows:

<<fullmodelgradate,echo=FALSE,results=tex>>=
grfull <- lm(Five.Year.Bachelors.Graduation.Rate~.,data=GradRate)
summ <- summary(lm(Five.Year.Bachelors.Graduation.Rate~.,data=GradRate))
print(xtable(summ,caption=paste0("F = ",round(summ$fstatistic,4)[1]," (n = ",length(GradRate[,1])," on ",summ$df[2]," degrees of freedom)")))
@

The first thing we should do is examine scatter plots of the five year graduation rate with other, non-binary variables in the reduced dataset, just to get a sense of what is going on.

<<pairs,echo=FALSE,fig=TRUE,>>=
require(reshape2)
qdata <- melt(GradRate[setdiff(names(GradRate),c("Size.Under.1000",
                     "Mid.East",
                     "Distant.Degree.of.Urbanization",
                     "UgradProfile.FullTime.MoreSelective.HighTransfer",
                     "UgradProfile.FullTime.MoreSelective.LowTransfer",
                     "UgradProfile.FullTime.Selective.HighTransfer",
                     "UgradProfile.FullTime.Selective.LowTransfer",
                     "UgradProfile.Medium.FullTime.Selective.Inclusive",
                     "SizeSetting.Large.FourYear.NotResidential",
                     "SizeSetting.Medium.FourYear.NotResidential",
                     "SizeSetting.Small.FourYear.NotResidential",
                     "SizeSetting.Small.FourYear.Residential",
                     "SizeSetting.VSmall.FourYear,NotResidential"
                     ))],id.vars=c("Five.Year.Bachelors.Graduation.Rate"))
group1 <- c("Tuition.Fees.2009.2010",
                     "Tuition.Fees.2010.2011",
            "Undergraduate.Enrollment",
                     "First.Time.Certificate.Seeking.Ugrad.Enrollment",
                     "First.Time.Full.Time.Certificate.Seeking.Ugrad.Enrollment",
                     "Percent.Total.Enrollment.White",
                     "Full.Time.Retention.Rate.2011",
                     "Bachelors.Degrees.Awarded")
group2 <- c("Percent.First.Time.Full.Time.Ugrad.Pell.Grant.Recipients",
                     "Investment.Return.As.Percent.Core.Revenue",
                     "Endowment.Per.FTE.Enrollment",
                     "Male.Female.Full.Time.Admission.Yeild.Difference",
                     "Percent.First.Time.Transfer.Ugrad.Enrollment",
                     "Assistant.Percentage.Full.Prof.Salary",
                     "Percent.Average.Student.Loan.Of.Tuition.Ugrad")
g <- ggplot(aes(Five.Year.Bachelors.Graduation.Rate,value,group=variable),data=qdata[qdata$variable %in% group1,])
g + geom_point(size=1) + facet_wrap(~variable,scales="free") + theme(strip.text.x = element_text(size = 4)) + xlab("Graduation Rate") + ylab("")
@

<<scatter2,echo=FALSE,fig=TRUE>>=
g <- ggplot(aes(Five.Year.Bachelors.Graduation.Rate,value,group=variable),data=qdata[qdata$variable %in% group2,])
g + geom_point(size=1) + facet_wrap(~variable,scales="free") + theme(strip.text.x = element_text(size = 4)) + xlab("Graduation Rate") + ylab("")
@

It is clear from this excersize that our full model has several serious problems. There are two pairs of variables that are clearly very collinear. "Tuition.Fees.2009.2010" and "Tuition.Fees.2010.2011" as well as "First.Time.Certificate.Seeking.Ugrad.Enrollment" and "First.Time.Full.Time.Certificate.Seeking.Ugrad.Enrollment" are providing almost the same information to the model. This can be confirmed by computing the variance inflation factors for all the variables in the full model. Clearly one variable of each pair should be removed from the model.

It is also clear from this table that "Undergraduate.Enrollment" and "Bachelor.Degrees.Awarded" are also causing collinearity issues. One would suspect that an intstitution with a large undergraduate enrollment would also have a large number of bachelor degrees awarded. One of these pair should likely be removed as well.

<<vif,echo=FALSE,results=tex>>=
library(car)
vtable <- data.frame(Variable=names(vif(grfull)),VIF=vif(grfull))
row.names(vtable) = NULL
print(xtable(vtable))
@

Another obvious correction would be to include an indicator variable for public institutions back into the model. The scatter plot panel with tuition on the y axis and graduation rate on the x axis is just the same as our first scatter plot comparing the two. The is a very obvious interaction between tuition and an institution's identity as public or private.

One more obvious correction would be to add a variable transformations for endowment per FTE. Earlier scatter plots indicate a diminishing relationship between this variable and graduation rates. An appropriate transform for endowment per FTE appears to be a log transformation.

<<transforms,echo=FALSE,fig=TRUE>>=
qplot(GradRate$Five.Year.Bachelors.Graduation.Rate,log(GradRate$Endowment.Per.FTE.Enrollment),xlab="Graduation Rate", ylab="Log(Endowment Per FTE Enrollment)")
@

Before making these corrections though, we have one larger problem. There are several indicators that the residuals are not normally distributed, likely due to outliers. A qq plot of the residuals suggests that they are distributed with heavy tails.

<<qqplot,echo=FALSE,fig=TRUE>>=
qplot(sample=grfull$residuals,stat="stat_qq")
@

\subsection{Outlier Removal}

A histogram of the studentized deleted residuals would suggest that we have several outliers. After calculating the bonferroni critical value for outliers, we can assume that the following observations for five year graduation rate should be removed from the dataset. Note that I have set the $\alpha$ level at $\alpha = 0.10$ for the Bonferroni test.

<<residuals,fig=TRUE,results=tex>>=
library(MASS)
stud.del.res <- studres(grfull)
qplot(stud.del.res,xlab="Studentized Deleted Residuals",binwidth=0.05)
alpha <- 0.1
ct <- qt(1-alpha/(2*length(stud.del.res)),length(stud.del.res) - length(grfull$coefficients))
groutliers <- which(abs(stud.del.res) > ct)
print(xtable(data.frame(Institutions = rownames(GradRate)[which(abs(stud.del.res) > ct)])))
@

The predictor variables also have outliers. We use the hat matrix to find them:

<<residualxes,results=tex>>=
diagonal <- lm.influence(grfull)$hat
threshold <- 2*(length(grfull$coefficients) - 1)/length(grfull$model$Five.Year.Bachelors.Graduation.Rate)
xoutliers <- which(diagonal > threshold)
print(xtable(data.frame(Institutions = rownames(GradRate)[xoutliers]),))
@

Now let's remove these from our full model and see if our residuals are more normally distributed.

<<removeoutliers,results=tex>>=
grfull_nouts <- lm(Five.Year.Bachelors.Graduation.Rate~.,data=GradRate[-c(groutliers,xoutliers),setdiff(names(GradRate),c("SizeSetting.VSmall.FourYear.NotResidential"))])
grfull_noutssumm <- summary(grfull_nouts)
print(xtable(grfull_noutssumm,caption=paste0("F = ",round(grfull_noutssumm$fstatistic,4)[1]," (n = ",length(grfull_nouts$model[,1])," on ",grfull_noutssumm$df[2]," degrees of freedom)")))
@

<<qqplotnoouts,echo=FALSE,fig=TRUE>>=
qplot(sample=grfull_nouts$residuals,stat="stat_qq")
@

It appears that our residuals are now normally distributed. Now we can make the apply corrections we noticed necessary in our initial model.

<<addbackprivate,echo=FALSE>>=
GradRate$Private <- sapply(row.names(GradRate),function(x) {
  want <- as.character(data$HD2011.Control.of.institution[row.names(data) == x])
  if (want == "Public") {
    return(1L)
  }
  else {
    return(0L)
  }
}) 
@

\subsection{Modeling}

Now that we have identified outliers in the data, we can estimate the model, incorporating the transformation to endowment per FTE and the interaction of tuition and fees with an institution's status as public or private.

<<reduceit,echo=FALSE,results=tex>>=
GradRate.m <- GradRate[-c(groutliers,xoutliers),setdiff(names(GradRate),c("Tuition.Fees.2009.2010", "First.Time.Certificate.Seeking.Ugrad.Enrollment", "Bachelors.Degrees.Awarded","SizeSetting.VSmall.FourYear.NotResidential"))]
grred <- lm(Five.Year.Bachelors.Graduation.Rate~. + Tuition.Fees.2010.2011*Private + I(log(Endowment.Per.FTE.Enrollment)) - Endowment.Per.FTE.Enrollment,data=GradRate.m)
grredsum <- summary(grred)
print(xtable(grredsum,caption=paste0("F = ",round(grredsum$fstatistic,4)[1]," (n = ",length(GradRate[,1])," on ",grredsum$df[2]," degrees of freedom)")))
@

Some coefficients have lost individual significance of thier coefficients. Scaling of the number of first time certificate seeking undergrads aids it's significance, but others are not aided. It may be necessary to remove them from the model. Additionally, computing the VIF statistic again shows that the tuition and fees interaction with public or private status, as well as undegraduate enrollment and first time certificate seeking undergrad enrollment are causing multicollinearity issues. Centering only appears to make the interaction term's contribution to the model's collinearity issues greater according to the VIF statistic, so we will live with that. We will now test if we can remove the first time certificate seeking undegrad enrollment variable.

<<damnftests>>=
grred.r <- lm(Five.Year.Bachelors.Graduation.Rate~. + Tuition.Fees.2010.2011*Private + I(log(Endowment.Per.FTE.Enrollment)) - Endowment.Per.FTE.Enrollment - First.Time.Full.Time.Certificate.Seeking.Ugrad.Enrollment,data=GradRate.m)
grred.rsum <- summary(grred.r)
F_star <- ((deviance(grred.r) - deviance(grred)) /
             ((length(grred$model$Five.Year.Bachelors.Graduation.Rate) - grred.rsum$df[1]) -
                (length(grred$model$Five.Year.Bachelors.Graduation.Rate) - grredsum$df[1]))) /
  (deviance(grred)/length(grred$model$Five.Year.Bachelors.Graduation.Rate) - grredsum$df[1])
cv <- qf(0.99,1,length(grred$model$Five.Year.Bachelors.Graduation.Rate)-grredsum$df[1])
F_star < cv
@

$F^*$ is greater than the critical value of $\Sexpr{cv}$ so we cannot remove the first time certificate seeking undergrad variable, the next test shows that we can remove all three of the variables endowment per FTE, the percentage that the average student loan is of tuition, and the percent of first time undgrad transfers enrolled.

<<damnftests2>>=
grred.r <- lm(Five.Year.Bachelors.Graduation.Rate~. + Tuition.Fees.2010.2011*Private - Endowment.Per.FTE.Enrollment - Percent.Average.Student.Loan.Of.Tuition.Ugrad - Percent.First.Time.Transfer.Ugrad.Enrollment,data=GradRate.m)
grred.rsum <- summary(grred.r)
F_star <- ((deviance(grred.r) - deviance(grred)) /
             ((length(grred$model$Five.Year.Bachelors.Graduation.Rate) - grred.rsum$df[1]) -
                (length(grred$model$Five.Year.Bachelors.Graduation.Rate) - grredsum$df[1]))) /
  (deviance(grred)/length(grred$model$Five.Year.Bachelors.Graduation.Rate) - grredsum$df[1])
cv <- qf(0.99,3,length(grred$model$Five.Year.Bachelors.Graduation.Rate)-grredsum$df[1])
F_star < cv
@

<<finalmodelresults,echo=FALSE,results=tex>>=
print(xtable(grred.rsum,caption=paste0("F = ",round(grred.rsum$fstatistic,4)[1]," (n = ",length(grred.r$model[,1])," on ",grred.rsum$df[2]," degrees of freedom)")))
@

We still have one more model problem to deal with if we are concerned about using our model for inference - heterskedasticity. The model exhibits heterskedasticity according the Breusch-Pagan test. We can quickly correct for this by using robust regression estimation.

<<bptest,results=tex>>=
library(lmtest)
bp <- bptest(grred.r)
bp <- data.frame(`Breusch-Pagan Statistic` = bp$statistic,
                 `Degrees of Freedom` = bp$parameter,
                 `Test` = bp$method[1],
                 `P Value` = bp$p.value,
                 row.names=NULL,check.rows=F,check.names=F,stringsAsFactors=F
                 )
print(xtable(bp))
@

<<robustestimate,results=tex>>=
robustestimate <- rlm(Five.Year.Bachelors.Graduation.Rate~. + Tuition.Fees.2010.2011*Private - Endowment.Per.FTE.Enrollment - Percent.Average.Student.Loan.Of.Tuition.Ugrad - Percent.First.Time.Transfer.Ugrad.Enrollment,data=GradRate.m)
robustsumm <- summary(robustestimate)
print(xtable(robustsumm$coefficients,caption=paste0("Residual Standard Error = ",round(robustsumm$sigma,4)," (n = ",length(robustestimate$model[,1])," on ",robustsumm$df[2]," degrees of freedom)")))
@

\subsection{Intepretation and Inference}

%-------------------------------------------
\section{Conclusion}
%-------------------------------------------

%-------------------------------------------
\section{References}
%-------------------------------------------

%-------------------------------------------
\section{Appendix}
%-------------------------------------------

\end{document}